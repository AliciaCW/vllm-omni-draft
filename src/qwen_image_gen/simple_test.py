#!/usr/bin/env python3
"""
ç®€åŒ–æµ‹è¯•è„šæœ¬ï¼šéªŒè¯ QwenImage é›†æˆçš„æ ¸å¿ƒåŠŸèƒ½
"""

import os
import sys
import torch

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))


def test_basic_imports():
    """æµ‹è¯•åŸºæœ¬å¯¼å…¥åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•åŸºæœ¬å¯¼å…¥...")

    try:
        from qwen_image_gen import create_qwen_image_config
        print("âœ… é…ç½®å¯¼å…¥æˆåŠŸ")

        from qwen_image_gen.types import QwenImageInputs, QwenImageTask, QwenImageOutputMode
        print("âœ… ç±»å‹å¯¼å…¥æˆåŠŸ")

        return True
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_config_creation():
    """æµ‹è¯•é…ç½®åˆ›å»º"""
    print("\nğŸ§ª æµ‹è¯•é…ç½®åˆ›å»º...")

    try:
        from qwen_image_gen import create_qwen_image_config

        config = create_qwen_image_config(
            model_id="test-model",
            max_batch_size=2
        )

        print(f"âœ… é…ç½®åˆ›å»ºæˆåŠŸ: {config.model_id}")
        print(f"   - æ‰¹æ¬¡å¤§å°: {config.max_batch_size}")
        print(f"   - è®¾å¤‡: {config.device}")
        print(f"   - æ•°æ®ç±»å‹: {config.dtype}")

        return True
    except Exception as e:
        print(f"âŒ é…ç½®åˆ›å»ºå¤±è´¥: {e}")
        return False


def test_types_creation():
    """æµ‹è¯•ç±»å‹åˆ›å»º"""
    print("\nğŸ§ª æµ‹è¯•ç±»å‹åˆ›å»º...")

    try:
        from qwen_image_gen.types import QwenImageInputs, QwenImageTask, QwenImageOutputMode

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 1
        seq_len = 77
        embed_dim = 768
        latent_channels = 4
        latent_height = 64
        latent_width = 64

        prompt_embeds = torch.randn(batch_size, seq_len, embed_dim)
        prompt_mask = torch.ones(batch_size, seq_len, dtype=torch.bool)
        image_latents = torch.randn(
            batch_size, latent_channels, latent_height, latent_width)
        timesteps = torch.linspace(1.0, 0.0, steps=10).long()

        # åˆ›å»ºè¾“å…¥å¯¹è±¡
        qwen_inputs = QwenImageInputs(
            prompt_embeds=prompt_embeds,
            prompt_embeds_mask=prompt_mask,
            image_latents=image_latents,
            timesteps=timesteps,
            task=QwenImageTask.TEXT_TO_IMAGE,
            output_mode=QwenImageOutputMode.PIXELS
        )

        print(f"âœ… è¾“å…¥å¯¹è±¡åˆ›å»ºæˆåŠŸ")
        print(f"   - ä»»åŠ¡ç±»å‹: {qwen_inputs.task}")
        print(f"   - è¾“å‡ºæ¨¡å¼: {qwen_inputs.output_mode}")
        print(f"   - å¼•å¯¼æ¯”ä¾‹: {qwen_inputs.guidance_scale}")
        print(f"   - æ¨ç†æ­¥æ•°: {qwen_inputs.num_inference_steps}")

        return True
    except Exception as e:
        print(f"âŒ ç±»å‹åˆ›å»ºå¤±è´¥: {e}")
        return False


def test_processor_basic():
    """æµ‹è¯•å¤„ç†å™¨åŸºæœ¬åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•å¤„ç†å™¨åŸºæœ¬åŠŸèƒ½...")

    try:
        from qwen_image_gen.processor import QwenImageGenProcessor

        # åˆ›å»ºå¤„ç†å™¨
        processor = QwenImageGenProcessor()
        print("âœ… å¤„ç†å™¨åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•å‚æ•°æå–
        test_kwargs = {
            "guidance_scale": 5.0,
            "num_inference_steps": 20,
            "height": 256,
            "width": 256
        }

        params = processor._extract_generation_params(test_kwargs)
        print(f"âœ… å‚æ•°æå–æˆåŠŸ: {len(params)} ä¸ªå‚æ•°")

        return True
    except Exception as e:
        print(f"âŒ å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç®€åŒ–æµ‹è¯•...")

    tests = [
        test_basic_imports,
        test_config_creation,
        test_types_creation,
        test_processor_basic,
    ]

    passed = 0
    total = len(tests)

    for test in tests:
        if test():
            passed += 1

    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
